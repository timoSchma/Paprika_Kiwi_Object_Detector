{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'../..')  # add project root to PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supress tensorflow depreciation warnings\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "from src.model import TinyYoloV3, train_test_split\n",
    "from src.preprocessing import JSONUtil\n",
    "from pathlib import Path\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../../data/'\n",
    "annotation_data = JSONUtil.read(Path(data_path, \"Master.json\"))\n",
    "weights_path = '../../models/pre_trained_weights/tiny-yoloV3.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the Random Seeds\n",
    "For deterministic execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seeds\n",
    "tf.random.set_random_seed(4321)\n",
    "np.random.seed(1459)\n",
    "split_seed = 2345"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Prepare the Data\n",
    "Split the data into a test, validation and training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train-Test split\n",
    "test_split = 0.1\n",
    "train_val_data, test_data = train_test_split(annotation_data, test_split, split_seed)\n",
    "\n",
    "# Train-Validation split\n",
    "validation_split = 0.2\n",
    "training_data, validation_data = train_test_split(train_val_data, validation_split, split_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning: Freezing followed by fine-tuning the whole model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "lr_freeze = 10**-2\n",
    "lr_fine_tuning = 10**-6\n",
    "epochs_freeze = 200\n",
    "epochs_fine_tuning = 200\n",
    "\n",
    "# Output paths\n",
    "out_path_freeze = \"model_0908.h5\"\n",
    "out_path_fine_tuning = '../../models/custom_trained_weights/model_1308_fine_tune.h5'\n",
    "out_path_checkpoints =\"weights.best.hdf5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau,ModelCheckpoint\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20, restore_best_weights = True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=4, min_lr=0.0000001)\n",
    "checkpoint = ModelCheckpoint(out_path_checkpoints, monitor='val_loss', verbose=0, save_best_only=True)\n",
    "callbacks = [early_stopping, reduce_lr, checkpoint]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "# Set Keras to learning-mode --> fix constantly adapting batch-normalizations\n",
    "K.set_learning_phase(1)\n",
    "\n",
    "# Setup Model\n",
    "model = TinyYoloV3(path = weights_path, pre_trained_weights = True)\n",
    "model.replace_output_layers()\n",
    "model.training_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "jittering_params = {\n",
    "        \"rotation_probability\": 0.41196905003193296,\n",
    "        \"jittering_probability\": 0.7701831052109321,\n",
    "        \"jittering_range\": {\n",
    "            \"hue\": 0.9058760880738045,\n",
    "            \"sat\": 0.6951054624889021,\n",
    "            \"val\": 0.8243935344646571\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 200 epochs on 926 samples with 232 validation samples and batch size 16.\n",
      "Epoch 1/200\n",
      "57/57 [==============================] - 27s 471ms/step - loss: 60.1667 - val_loss: 18.8437\n",
      "Epoch 2/200\n",
      "57/57 [==============================] - 22s 383ms/step - loss: 17.2372 - val_loss: 16.2969\n",
      "Epoch 3/200\n",
      "57/57 [==============================] - 22s 394ms/step - loss: 15.6213 - val_loss: 15.5245\n",
      "Epoch 4/200\n",
      "57/57 [==============================] - 23s 395ms/step - loss: 14.2641 - val_loss: 14.6396\n",
      "Epoch 5/200\n",
      "57/57 [==============================] - 22s 393ms/step - loss: 14.1435 - val_loss: 14.1891\n",
      "Epoch 6/200\n",
      "57/57 [==============================] - 22s 391ms/step - loss: 13.4206 - val_loss: 13.6441\n",
      "Epoch 7/200\n",
      "57/57 [==============================] - 23s 409ms/step - loss: 12.9689 - val_loss: 13.2816\n",
      "Epoch 8/200\n",
      "57/57 [==============================] - 23s 400ms/step - loss: 12.8624 - val_loss: 13.3276\n",
      "Epoch 9/200\n",
      "57/57 [==============================] - 23s 409ms/step - loss: 12.6854 - val_loss: 12.8460\n",
      "Epoch 10/200\n",
      "57/57 [==============================] - 22s 394ms/step - loss: 13.1696 - val_loss: 14.1321\n",
      "Epoch 11/200\n",
      "57/57 [==============================] - 24s 413ms/step - loss: 13.0064 - val_loss: 12.9323\n",
      "Epoch 12/200\n",
      "57/57 [==============================] - 23s 398ms/step - loss: 13.2029 - val_loss: 13.3036\n",
      "Epoch 13/200\n",
      "57/57 [==============================] - 22s 391ms/step - loss: 13.6944 - val_loss: 16.0807\n",
      "Epoch 14/200\n",
      "57/57 [==============================] - 22s 394ms/step - loss: 12.6632 - val_loss: 11.9515\n",
      "Epoch 15/200\n",
      "57/57 [==============================] - 23s 409ms/step - loss: 11.4035 - val_loss: 11.9512\n",
      "Epoch 16/200\n",
      "57/57 [==============================] - 23s 405ms/step - loss: 11.0622 - val_loss: 11.5735\n",
      "Epoch 17/200\n",
      "57/57 [==============================] - 25s 430ms/step - loss: 10.7629 - val_loss: 11.6007\n",
      "Epoch 18/200\n",
      "57/57 [==============================] - 25s 436ms/step - loss: 10.6758 - val_loss: 11.1480\n",
      "Epoch 19/200\n",
      "57/57 [==============================] - 26s 451ms/step - loss: 10.5435 - val_loss: 11.3612\n",
      "Epoch 20/200\n",
      "57/57 [==============================] - 29s 502ms/step - loss: 10.5530 - val_loss: 11.1210\n",
      "Epoch 21/200\n",
      "57/57 [==============================] - 24s 422ms/step - loss: 10.4242 - val_loss: 11.1908\n",
      "Epoch 22/200\n",
      "57/57 [==============================] - 24s 419ms/step - loss: 10.4093 - val_loss: 11.1827\n",
      "Epoch 23/200\n",
      "57/57 [==============================] - 26s 457ms/step - loss: 10.1684 - val_loss: 11.2186\n",
      "Epoch 24/200\n",
      "57/57 [==============================] - 25s 443ms/step - loss: 10.2762 - val_loss: 10.8282\n",
      "Epoch 25/200\n",
      "57/57 [==============================] - 23s 406ms/step - loss: 10.3176 - val_loss: 10.8966\n",
      "Epoch 26/200\n",
      "57/57 [==============================] - 23s 402ms/step - loss: 10.3144 - val_loss: 10.8935\n",
      "Epoch 27/200\n",
      "57/57 [==============================] - 23s 396ms/step - loss: 10.1357 - val_loss: 10.8512\n",
      "Epoch 28/200\n",
      "57/57 [==============================] - 23s 406ms/step - loss: 10.1001 - val_loss: 10.7713\n",
      "Epoch 29/200\n",
      "57/57 [==============================] - 24s 420ms/step - loss: 10.1537 - val_loss: 10.8081\n",
      "Epoch 30/200\n",
      "57/57 [==============================] - 23s 398ms/step - loss: 9.9781 - val_loss: 10.4643\n",
      "Epoch 31/200\n",
      "57/57 [==============================] - 23s 400ms/step - loss: 10.1771 - val_loss: 10.7239\n",
      "Epoch 32/200\n",
      "57/57 [==============================] - 23s 397ms/step - loss: 10.0173 - val_loss: 10.7300\n",
      "Epoch 33/200\n",
      "57/57 [==============================] - 22s 395ms/step - loss: 10.0727 - val_loss: 10.8202\n",
      "Epoch 34/200\n",
      "57/57 [==============================] - 22s 395ms/step - loss: 10.0186 - val_loss: 11.0064\n",
      "Epoch 35/200\n",
      "57/57 [==============================] - 23s 403ms/step - loss: 9.9675 - val_loss: 10.4165\n",
      "Epoch 36/200\n",
      "57/57 [==============================] - 22s 390ms/step - loss: 9.9099 - val_loss: 10.3823\n",
      "Epoch 37/200\n",
      "57/57 [==============================] - 23s 401ms/step - loss: 9.9614 - val_loss: 10.3467\n",
      "Epoch 38/200\n",
      "57/57 [==============================] - 23s 402ms/step - loss: 9.8465 - val_loss: 10.6060\n",
      "Epoch 39/200\n",
      "57/57 [==============================] - 22s 389ms/step - loss: 9.8250 - val_loss: 10.5698\n",
      "Epoch 40/200\n",
      "57/57 [==============================] - 23s 408ms/step - loss: 9.8905 - val_loss: 10.6315\n",
      "Epoch 41/200\n",
      "57/57 [==============================] - 23s 395ms/step - loss: 9.8637 - val_loss: 10.7568\n",
      "Epoch 42/200\n",
      "57/57 [==============================] - 22s 391ms/step - loss: 9.8026 - val_loss: 10.6371\n",
      "Epoch 43/200\n",
      "57/57 [==============================] - 24s 422ms/step - loss: 9.9448 - val_loss: 10.5706\n",
      "Epoch 44/200\n",
      "57/57 [==============================] - 23s 401ms/step - loss: 9.7277 - val_loss: 10.4275\n",
      "Epoch 45/200\n",
      "57/57 [==============================] - 22s 393ms/step - loss: 9.7475 - val_loss: 10.5166\n",
      "Epoch 46/200\n",
      "57/57 [==============================] - 23s 406ms/step - loss: 9.8304 - val_loss: 10.6603\n",
      "Epoch 47/200\n",
      "57/57 [==============================] - 23s 399ms/step - loss: 9.8012 - val_loss: 10.4765\n",
      "Epoch 48/200\n",
      "57/57 [==============================] - 24s 416ms/step - loss: 9.6828 - val_loss: 10.2509\n",
      "Epoch 49/200\n",
      "57/57 [==============================] - 23s 396ms/step - loss: 9.9291 - val_loss: 10.4685\n",
      "Epoch 50/200\n",
      "57/57 [==============================] - 23s 401ms/step - loss: 9.8586 - val_loss: 10.6032\n",
      "Epoch 51/200\n",
      "57/57 [==============================] - 23s 395ms/step - loss: 9.7910 - val_loss: 10.3739\n",
      "Epoch 52/200\n",
      "57/57 [==============================] - 23s 396ms/step - loss: 9.6860 - val_loss: 10.8173\n",
      "Epoch 53/200\n",
      "57/57 [==============================] - 25s 447ms/step - loss: 9.7527 - val_loss: 10.1445\n",
      "Epoch 54/200\n",
      "57/57 [==============================] - 23s 405ms/step - loss: 9.8282 - val_loss: 10.3878\n",
      "Epoch 55/200\n",
      "57/57 [==============================] - 23s 410ms/step - loss: 9.7949 - val_loss: 10.5045\n",
      "Epoch 56/200\n",
      "57/57 [==============================] - 24s 419ms/step - loss: 9.8212 - val_loss: 10.6729\n",
      "Epoch 57/200\n",
      "57/57 [==============================] - 22s 383ms/step - loss: 9.7754 - val_loss: 10.5003\n",
      "Epoch 58/200\n",
      "57/57 [==============================] - 23s 412ms/step - loss: 9.7961 - val_loss: 10.7044\n",
      "Epoch 59/200\n",
      "57/57 [==============================] - 23s 405ms/step - loss: 9.7992 - val_loss: 10.4270\n",
      "Epoch 60/200\n",
      "57/57 [==============================] - 22s 387ms/step - loss: 9.7102 - val_loss: 10.7882\n",
      "Epoch 61/200\n",
      "57/57 [==============================] - 23s 401ms/step - loss: 9.7421 - val_loss: 10.4048\n",
      "Epoch 62/200\n",
      "57/57 [==============================] - 22s 394ms/step - loss: 9.7952 - val_loss: 10.4199\n",
      "Epoch 63/200\n",
      "57/57 [==============================] - 22s 391ms/step - loss: 9.7908 - val_loss: 10.5499\n",
      "Epoch 64/200\n",
      "57/57 [==============================] - 22s 387ms/step - loss: 9.9330 - val_loss: 10.4467\n",
      "Epoch 65/200\n",
      "57/57 [==============================] - 23s 398ms/step - loss: 9.8559 - val_loss: 10.5739\n",
      "Epoch 66/200\n",
      "57/57 [==============================] - 23s 406ms/step - loss: 9.7553 - val_loss: 10.3970\n",
      "Epoch 67/200\n",
      "57/57 [==============================] - 23s 412ms/step - loss: 9.8712 - val_loss: 10.3961\n",
      "Epoch 68/200\n",
      "57/57 [==============================] - 23s 395ms/step - loss: 9.7004 - val_loss: 10.5526\n",
      "Epoch 69/200\n",
      "57/57 [==============================] - 23s 400ms/step - loss: 9.7222 - val_loss: 10.6162\n",
      "Epoch 70/200\n",
      "57/57 [==============================] - 22s 391ms/step - loss: 9.7831 - val_loss: 10.4451\n",
      "Epoch 71/200\n",
      "57/57 [==============================] - 25s 436ms/step - loss: 9.8247 - val_loss: 10.6136\n",
      "Epoch 72/200\n",
      "57/57 [==============================] - 22s 390ms/step - loss: 9.8210 - val_loss: 10.4348\n",
      "Epoch 73/200\n",
      "57/57 [==============================] - 23s 398ms/step - loss: 9.7329 - val_loss: 10.5007\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00073: early stopping\n"
     ]
    }
   ],
   "source": [
    "# freeze selected layers\n",
    "model.freeze_all_but_output()\n",
    " \n",
    "# start training (Transfer Learning)\n",
    "history_freeze = model.train(training_data, validation_data, data_path, lr_freeze, batch_size, \n",
    "                             epochs_freeze, out_path=out_path_freeze, jittering_params = jittering_params,\n",
    "                             callbacks = callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 200 epochs on 926 samples with 232 validation samples and batch size 16.\n",
      "Epoch 201/400\n",
      "57/57 [==============================] - 27s 470ms/step - loss: 9.8346 - val_loss: 10.4142\n",
      "Epoch 202/400\n",
      "57/57 [==============================] - 23s 412ms/step - loss: 9.7917 - val_loss: 10.3891\n",
      "Epoch 203/400\n",
      "57/57 [==============================] - 24s 417ms/step - loss: 9.5251 - val_loss: 10.5345\n",
      "Epoch 204/400\n",
      "57/57 [==============================] - 24s 413ms/step - loss: 9.6556 - val_loss: 10.3409\n",
      "Epoch 205/400\n",
      "57/57 [==============================] - 24s 412ms/step - loss: 9.7791 - val_loss: 10.5295\n",
      "Epoch 206/400\n",
      "57/57 [==============================] - 24s 413ms/step - loss: 9.5288 - val_loss: 10.4481\n",
      "Epoch 207/400\n",
      "57/57 [==============================] - 24s 423ms/step - loss: 9.5143 - val_loss: 10.4469\n",
      "Epoch 208/400\n",
      "57/57 [==============================] - 24s 412ms/step - loss: 9.4616 - val_loss: 10.3842\n",
      "Epoch 209/400\n",
      "57/57 [==============================] - 23s 402ms/step - loss: 9.4127 - val_loss: 10.3463\n",
      "Epoch 210/400\n",
      "57/57 [==============================] - 24s 422ms/step - loss: 9.4755 - val_loss: 10.0558\n",
      "Epoch 211/400\n",
      "57/57 [==============================] - 23s 411ms/step - loss: 9.4435 - val_loss: 10.1911\n",
      "Epoch 212/400\n",
      "57/57 [==============================] - 23s 409ms/step - loss: 9.4153 - val_loss: 10.4930\n",
      "Epoch 213/400\n",
      "57/57 [==============================] - 26s 451ms/step - loss: 9.4709 - val_loss: 10.2217\n",
      "Epoch 214/400\n",
      "57/57 [==============================] - 26s 455ms/step - loss: 9.3343 - val_loss: 10.2247\n",
      "Epoch 215/400\n",
      "57/57 [==============================] - 26s 456ms/step - loss: 9.4254 - val_loss: 10.2195\n",
      "Epoch 216/400\n",
      "57/57 [==============================] - 26s 452ms/step - loss: 9.3616 - val_loss: 9.9141\n",
      "Epoch 217/400\n",
      "57/57 [==============================] - 25s 447ms/step - loss: 9.4734 - val_loss: 10.1157\n",
      "Epoch 218/400\n",
      "57/57 [==============================] - 24s 414ms/step - loss: 9.4184 - val_loss: 10.4470\n",
      "Epoch 219/400\n",
      "57/57 [==============================] - 24s 414ms/step - loss: 9.3358 - val_loss: 10.2436\n",
      "Epoch 220/400\n",
      "57/57 [==============================] - 24s 424ms/step - loss: 9.4312 - val_loss: 10.0172\n",
      "Epoch 221/400\n",
      "57/57 [==============================] - 24s 414ms/step - loss: 9.3867 - val_loss: 10.4827\n",
      "Epoch 222/400\n",
      "57/57 [==============================] - 23s 409ms/step - loss: 9.4483 - val_loss: 10.1783\n",
      "Epoch 223/400\n",
      "57/57 [==============================] - 24s 421ms/step - loss: 9.4059 - val_loss: 10.3439\n",
      "Epoch 224/400\n",
      "57/57 [==============================] - 23s 411ms/step - loss: 9.3360 - val_loss: 10.1331\n",
      "Epoch 225/400\n",
      "57/57 [==============================] - 23s 406ms/step - loss: 9.3717 - val_loss: 10.1171\n",
      "Epoch 226/400\n",
      "57/57 [==============================] - 23s 411ms/step - loss: 9.3472 - val_loss: 10.2309\n",
      "Epoch 227/400\n",
      "57/57 [==============================] - 24s 417ms/step - loss: 9.3954 - val_loss: 10.2502\n",
      "Epoch 228/400\n",
      "57/57 [==============================] - 24s 417ms/step - loss: 9.2837 - val_loss: 10.4312\n",
      "Epoch 229/400\n",
      "57/57 [==============================] - 24s 415ms/step - loss: 9.2845 - val_loss: 10.1957\n",
      "Epoch 230/400\n",
      "57/57 [==============================] - 24s 420ms/step - loss: 9.5204 - val_loss: 10.3016\n",
      "Epoch 231/400\n",
      "57/57 [==============================] - 24s 413ms/step - loss: 9.4436 - val_loss: 10.3181\n",
      "Epoch 232/400\n",
      "57/57 [==============================] - 24s 418ms/step - loss: 9.5438 - val_loss: 10.3420\n",
      "Epoch 233/400\n",
      "57/57 [==============================] - 24s 419ms/step - loss: 9.4050 - val_loss: 10.1006\n",
      "Epoch 234/400\n",
      "57/57 [==============================] - 24s 415ms/step - loss: 9.3882 - val_loss: 10.1146\n",
      "Epoch 235/400\n",
      "57/57 [==============================] - 24s 417ms/step - loss: 9.3380 - val_loss: 10.2993\n",
      "Epoch 236/400\n",
      "57/57 [==============================] - 24s 413ms/step - loss: 9.3376 - val_loss: 10.2096\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00236: early stopping\n"
     ]
    }
   ],
   "source": [
    "model.unfreeze()\n",
    "\n",
    "history_fine_tuning = model.train(training_data, validation_data, data_path, lr_fine_tuning, batch_size, \n",
    "                                  epochs=epochs_freeze+epochs_fine_tuning, initial_epoch=epochs_freeze, \n",
    "                                  out_path=out_path_fine_tuning, jittering_params = jittering_params,\n",
    "                                  callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Model \n",
    "### Plot the Loss History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_loss(histories):\n",
    "    loss = [loss_value for history in histories \n",
    "                       for loss_value in history.history['loss']]\n",
    "    val_loss = [loss_value for history in histories \n",
    "                           for loss_value in history.history['val_loss']]\n",
    "    plt.plot(loss, label='Loss')\n",
    "    plt.plot(val_loss, label='Val Loss')\n",
    "    plt.title('Loss per Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss([history_freeze, history_fine_tuning])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain the Train and Test Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.537859229123242"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# obtain train-error\n",
    "model.evaluate(train_val_data, data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.127773727557456"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# obtain test-error\n",
    "model.evaluate(test_data, data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Grid Search for Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.grid_search import grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"freeze_learning_rate\": [1e-2],\n",
    "    \"freeze_batch_size\": [16],\n",
    "    \"freeze_epochs\": [1],\n",
    "    \"freeze_jittering_params\": [(0.5, 0.5, 0.1, 1.5, 1.5)],\n",
    "\n",
    "    \"fine_tuning_learning_rate\": [1e-4],\n",
    "    \"fine_tuning_batch_size\": [16],\n",
    "    \"fine_tuning_epochs\": [1],\n",
    "    \"fine_tuning_jittering_params\": [(0.5, 0.5, 0.1, 1.5, 1.5), (0, 0, 0.1, 1.5, 1.5)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "split = train_test_split(np.arange(len(train_val_data)), train_size=1 - validation_split, \n",
    "                         test_size=validation_split, random_state=split_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = grid_search(train_val_data, data_path, param_grid, cv=[split])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Transfer Learning: Bottleneck Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.bottleneck_features import BottleneckFeatures\n",
    "import keras.backend as K\n",
    "K.set_learning_phase(1)\n",
    "\n",
    "lr_bottleneck = 1e-3\n",
    "lr_freeze = 1e-3\n",
    "lr_fine_tuning = 1e-4\n",
    "\n",
    "epochs_bottleneck = 100\n",
    "epochs_freeze = 10\n",
    "epochs_fine_tuning = 10\n",
    "batch_size = 1\n",
    "\n",
    "out_path = None\n",
    "\n",
    "model = TinyYoloV3()\n",
    "model.replace_output_layers()\n",
    "model.training_mode()\n",
    "\n",
    "yolo_config = model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.model_selection\n",
    "\n",
    "indices = list(range(len(annotation_data)))\n",
    "training_indices, validation_indices = sklearn.model_selection.train_test_split(\n",
    "    indices, train_size=1 - validation_split, test_size=validation_split)\n",
    "\n",
    "\n",
    "training_data = {key: annotation_data[key] for i, key in enumerate(annotation_data)\n",
    "                 if i in training_indices}\n",
    "validation_data = {key: annotation_data[key] for i, key in enumerate(annotation_data)\n",
    "                   if i in validation_indices}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Bottleneck Features and Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottleneck_model, last_layer_model = model.create_bottleneck_and_last_layer_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottleneck_features = BottleneckFeatures()\n",
    "bottleneck_features.create_from_data(annotation_data, data_path, bottleneck_model, yolo_config)\n",
    "\n",
    "train_features, val_features = bottleneck_features.train_test_split(training_indices, \n",
    "                                                                    validation_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Last-Layer Model on bottleneck features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_bottleneck = 8\n",
    "\n",
    "train_gen = train_features.generator(batch_size_bottleneck, yolo_config)\n",
    "val_gen = val_features.generator(batch_size_bottleneck, yolo_config)\n",
    "data_len = len(training_indices), len(validation_indices)\n",
    "history_bottleneck = TinyYoloV3.train_model_wrapper(last_layer_model, (train_gen, val_gen), \n",
    "                                                    data_len, batch_size_bottleneck, \n",
    "                                                    lr_bottleneck, epochs_bottleneck)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training only the last layers with random augmented data (i.e. not bottleneck features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.freeze(range(42)) # TODO: select what to freeze\n",
    "history_freeze = model.train(training_data, validation_data, data_path, lr_freeze, \n",
    "                             batch_size, epochs_freeze, out_path=out_path, random=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final fine-tuning on all layers with lower learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.unfreeze()\n",
    "history_fine_tuning = model.train(training_data, validation_data, data_path, \n",
    "                                  lr_fine_tuning, batch_size, \n",
    "                                  epochs=epochs_freeze+epochs_fine_tuning, \n",
    "                                  initial_epoch=epochs_freeze, out_path=out_path, random=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss([history_bottleneck, history_freeze, history_fine_tuning])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
