{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore gpu\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all necessary packages and modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'../..')  # add project root to PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supress tensorflow depreciation warnings\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "from src.annotated_image import AnnotatedImage, Image\n",
    "from src.model import TinyYoloV3, train_test_split\n",
    "from src.model_utils import yolo_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path =  '../../models/custom_trained_weights/model_1308_custom_jittering.h5'\n",
    "image_dir = \"../../data/\"\n",
    "# set these two variables for selecting the inference mode\n",
    "using_nano_camera = True\n",
    "detect_on_space_keystroke = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.preprocessing import JSONUtil\n",
    "from pathlib import Path \n",
    "\n",
    "# get test images\n",
    "data_path = '../../data/'\n",
    "annotation_data = JSONUtil.read(Path(data_path, \"Master.json\"))\n",
    "\n",
    "# Train-Test split\n",
    "test_split = 0.1\n",
    "split_seed = 2345\n",
    "train_val_data, test_data = train_test_split(annotation_data, test_split, split_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate the object detector and perform some detections for demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TinyYoloV3(path=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_detect(model, image_path, rescale=False):\n",
    "    image = Image(path=image_path)\n",
    "    if rescale:\n",
    "        image.resize(*model.config.input_size)\n",
    "    img_box = model.detect(image, show=False)\n",
    "    \n",
    "    return img_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_match(true_box, predicted_boxes, confidence_threshold):\n",
    "    best_iou = 0\n",
    "    best_match = None\n",
    "    for i, box in enumerate(predicted_boxes):\n",
    "        if box.score < confidence_threshold:\n",
    "            continue\n",
    "        iou = true_box.iou(box)\n",
    "        if iou > best_iou and true_box.label == box.label:\n",
    "            best_iou = iou\n",
    "            best_match = i\n",
    "    return best_iou, best_match\n",
    "            \n",
    "\n",
    "def match_boxes(prediction, ground_truth, confidence_threshold):\n",
    "    # find best match for each ground truth box\n",
    "    matches = [find_best_match(true_box, prediction, confidence_threshold)\n",
    "               for true_box in ground_truth]\n",
    "    \n",
    "    # make sure no predicted box is assigned to multiple ground truth boxes\n",
    "    predicted_to_true_assignment = {\n",
    "        predicted_id: [(iou, true_id) for true_id, (iou, i) in enumerate(matches) \n",
    "                       if i == predicted_id]\n",
    "        for predicted_id in range(len(prediction))\n",
    "    }\n",
    "    # remove duplicate assignments\n",
    "    for predicted_id, assigned_boxes in predicted_to_true_assignment.items():\n",
    "        if len(assigned_boxes) > 1:\n",
    "            max_iou = max(assigned_boxes)[0]\n",
    "            for iou, true_id in assigned_boxes:\n",
    "                if iou != max_iou:\n",
    "                    matches[true_id] = 0, None\n",
    "    \n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_image(prediction, ground_truth, confidence_threshold, iou_threshold=0.5):\n",
    "    total_predicted_boxes = sum(1 for box in prediction if box.score > confidence_threshold)\n",
    "    total_ground_truth_boxes = len(ground_truth)\n",
    "    \n",
    "    matched_boxes = match_boxes(prediction, ground_truth, confidence_threshold)\n",
    "    correctly_predicted_boxes = sum(1 for iou, _ in matched_boxes if iou > iou_threshold)\n",
    "    \n",
    "    return correctly_predicted_boxes, total_predicted_boxes, total_ground_truth_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(correctly_predicted_boxes, total_predicted_boxes):\n",
    "    if total_predicted_boxes == 0:\n",
    "        return 0.0\n",
    "    return correctly_predicted_boxes / total_predicted_boxes\n",
    "\n",
    "def recall(correctly_predicted_boxes, total_ground_truth_boxes):\n",
    "    if total_ground_truth_boxes == 0:\n",
    "        return 0.0\n",
    "    return correctly_predicted_boxes / total_ground_truth_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overall_evaluation(predictions, ground_truths, confidence_threshold, class_name=None, \n",
    "                       iou_threshold=0.5):\n",
    "    global_evaluation = np.array([0, 0, 0])\n",
    "    for key in predictions:\n",
    "        prediction = [box for box in predictions[key].annotations \n",
    "                      if box.label == class_name or class_name is None]\n",
    "        ground_truth = [box for box in ground_truths[key].annotations\n",
    "                      if box.label == class_name or class_name is None]\n",
    "\n",
    "        evaluation = evaluate_image(prediction, ground_truth, confidence_threshold, iou_threshold)\n",
    "        global_evaluation += np.asarray(evaluation)\n",
    "\n",
    "    correctly_predicted_boxes, total_predicted_boxes, total_ground_truth_boxes = global_evaluation\n",
    "\n",
    "    p = precision(correctly_predicted_boxes, total_predicted_boxes)\n",
    "    r = recall(correctly_predicted_boxes, total_ground_truth_boxes)\n",
    "    \n",
    "    print(f\"TP        = {correctly_predicted_boxes}\")\n",
    "    print(f\"TP + FP   = {total_predicted_boxes}\")\n",
    "    print(f\"TP + FN   = {total_ground_truth_boxes}\")\n",
    "    print(f\"Precision = {p}\")\n",
    "    print(f\"Recall    = {r}\")\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.score = 0\n",
    "predictions = {key: load_and_detect(model, image_dir + key) for key in test_data}\n",
    "ground_truths = {key: AnnotatedImage(image_path=image_dir + key, annotation_dict=test_data) \n",
    "                for key in test_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confidence_threshold: 0.0\n",
      "Paprika:\n",
      "TP        = 140\n",
      "TP + FP   = 2580\n",
      "TP + FN   = 148\n",
      "Precision = 0.05426356589147287\n",
      "Recall    = 0.9459459459459459\n",
      "Kiwi:\n",
      "TP        = 103\n",
      "TP + FP   = 2580\n",
      "TP + FN   = 108\n",
      "Precision = 0.03992248062015504\n",
      "Recall    = 0.9537037037037037\n",
      "confidence_threshold: 0.1\n",
      "Paprika:\n",
      "TP        = 134\n",
      "TP + FP   = 199\n",
      "TP + FN   = 148\n",
      "Precision = 0.6733668341708543\n",
      "Recall    = 0.9054054054054054\n",
      "Kiwi:\n",
      "TP        = 90\n",
      "TP + FP   = 151\n",
      "TP + FN   = 108\n",
      "Precision = 0.5960264900662252\n",
      "Recall    = 0.8333333333333334\n",
      "confidence_threshold: 0.2\n",
      "Paprika:\n",
      "TP        = 126\n",
      "TP + FP   = 161\n",
      "TP + FN   = 148\n",
      "Precision = 0.782608695652174\n",
      "Recall    = 0.8513513513513513\n",
      "Kiwi:\n",
      "TP        = 80\n",
      "TP + FP   = 121\n",
      "TP + FN   = 108\n",
      "Precision = 0.6611570247933884\n",
      "Recall    = 0.7407407407407407\n",
      "confidence_threshold: 0.3\n",
      "Paprika:\n",
      "TP        = 113\n",
      "TP + FP   = 139\n",
      "TP + FN   = 148\n",
      "Precision = 0.8129496402877698\n",
      "Recall    = 0.7635135135135135\n",
      "Kiwi:\n",
      "TP        = 73\n",
      "TP + FP   = 100\n",
      "TP + FN   = 108\n",
      "Precision = 0.73\n",
      "Recall    = 0.6759259259259259\n",
      "confidence_threshold: 0.4\n",
      "Paprika:\n",
      "TP        = 105\n",
      "TP + FP   = 123\n",
      "TP + FN   = 148\n",
      "Precision = 0.8536585365853658\n",
      "Recall    = 0.7094594594594594\n",
      "Kiwi:\n",
      "TP        = 59\n",
      "TP + FP   = 80\n",
      "TP + FN   = 108\n",
      "Precision = 0.7375\n",
      "Recall    = 0.5462962962962963\n",
      "confidence_threshold: 0.5\n",
      "Paprika:\n",
      "TP        = 92\n",
      "TP + FP   = 108\n",
      "TP + FN   = 148\n",
      "Precision = 0.8518518518518519\n",
      "Recall    = 0.6216216216216216\n",
      "Kiwi:\n",
      "TP        = 55\n",
      "TP + FP   = 71\n",
      "TP + FN   = 108\n",
      "Precision = 0.7746478873239436\n",
      "Recall    = 0.5092592592592593\n",
      "confidence_threshold: 0.6\n",
      "Paprika:\n",
      "TP        = 75\n",
      "TP + FP   = 90\n",
      "TP + FN   = 148\n",
      "Precision = 0.8333333333333334\n",
      "Recall    = 0.5067567567567568\n",
      "Kiwi:\n",
      "TP        = 51\n",
      "TP + FP   = 63\n",
      "TP + FN   = 108\n",
      "Precision = 0.8095238095238095\n",
      "Recall    = 0.4722222222222222\n",
      "confidence_threshold: 0.7\n",
      "Paprika:\n",
      "TP        = 63\n",
      "TP + FP   = 74\n",
      "TP + FN   = 148\n",
      "Precision = 0.8513513513513513\n",
      "Recall    = 0.42567567567567566\n",
      "Kiwi:\n",
      "TP        = 43\n",
      "TP + FP   = 50\n",
      "TP + FN   = 108\n",
      "Precision = 0.86\n",
      "Recall    = 0.39814814814814814\n",
      "confidence_threshold: 0.8\n",
      "Paprika:\n",
      "TP        = 50\n",
      "TP + FP   = 56\n",
      "TP + FN   = 148\n",
      "Precision = 0.8928571428571429\n",
      "Recall    = 0.33783783783783783\n",
      "Kiwi:\n",
      "TP        = 33\n",
      "TP + FP   = 37\n",
      "TP + FN   = 108\n",
      "Precision = 0.8918918918918919\n",
      "Recall    = 0.3055555555555556\n",
      "confidence_threshold: 0.9\n",
      "Paprika:\n",
      "TP        = 26\n",
      "TP + FP   = 30\n",
      "TP + FN   = 148\n",
      "Precision = 0.8666666666666667\n",
      "Recall    = 0.17567567567567569\n",
      "Kiwi:\n",
      "TP        = 18\n",
      "TP + FP   = 20\n",
      "TP + FN   = 108\n",
      "Precision = 0.9\n",
      "Recall    = 0.16666666666666666\n",
      "confidence_threshold: 1.0\n",
      "Paprika:\n",
      "TP        = 0\n",
      "TP + FP   = 0\n",
      "TP + FN   = 148\n",
      "Precision = 0.0\n",
      "Recall    = 0.0\n",
      "Kiwi:\n",
      "TP        = 0\n",
      "TP + FP   = 0\n",
      "TP + FN   = 108\n",
      "Precision = 0.0\n",
      "Recall    = 0.0\n"
     ]
    }
   ],
   "source": [
    "precisions_paprika = []\n",
    "precisions_kiwi = []\n",
    "confidences = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "\n",
    "for confidence_threshold in confidences:\n",
    "    print(f\"confidence_threshold: {confidence_threshold}\")\n",
    "    print(\"Paprika:\")\n",
    "    p_paprika = overall_evaluation(predictions, ground_truths, confidence_threshold, \"Paprika\", 0.5)\n",
    "    print(\"Kiwi:\")\n",
    "    p_kiwi = overall_evaluation(predictions, ground_truths, confidence_threshold, \"Kiwi\", 0.5)\n",
    "    precisions_paprika.append(p_paprika)\n",
    "    precisions_kiwi.append(p_kiwi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confidence_threshold: 0.0\n",
      "TP        = 243\n",
      "TP + FP   = 5160\n",
      "TP + FN   = 256\n",
      "Precision = 0.04709302325581395\n",
      "Recall    = 0.94921875\n",
      "confidence_threshold: 0.1\n",
      "TP        = 224\n",
      "TP + FP   = 350\n",
      "TP + FN   = 256\n",
      "Precision = 0.64\n",
      "Recall    = 0.875\n",
      "confidence_threshold: 0.2\n",
      "TP        = 206\n",
      "TP + FP   = 282\n",
      "TP + FN   = 256\n",
      "Precision = 0.7304964539007093\n",
      "Recall    = 0.8046875\n",
      "confidence_threshold: 0.3\n",
      "TP        = 186\n",
      "TP + FP   = 239\n",
      "TP + FN   = 256\n",
      "Precision = 0.7782426778242678\n",
      "Recall    = 0.7265625\n",
      "confidence_threshold: 0.4\n",
      "TP        = 164\n",
      "TP + FP   = 203\n",
      "TP + FN   = 256\n",
      "Precision = 0.8078817733990148\n",
      "Recall    = 0.640625\n",
      "confidence_threshold: 0.5\n",
      "TP        = 147\n",
      "TP + FP   = 179\n",
      "TP + FN   = 256\n",
      "Precision = 0.8212290502793296\n",
      "Recall    = 0.57421875\n",
      "confidence_threshold: 0.6\n",
      "TP        = 126\n",
      "TP + FP   = 153\n",
      "TP + FN   = 256\n",
      "Precision = 0.8235294117647058\n",
      "Recall    = 0.4921875\n",
      "confidence_threshold: 0.7\n",
      "TP        = 106\n",
      "TP + FP   = 124\n",
      "TP + FN   = 256\n",
      "Precision = 0.8548387096774194\n",
      "Recall    = 0.4140625\n",
      "confidence_threshold: 0.8\n",
      "TP        = 83\n",
      "TP + FP   = 93\n",
      "TP + FN   = 256\n",
      "Precision = 0.8924731182795699\n",
      "Recall    = 0.32421875\n",
      "confidence_threshold: 0.9\n",
      "TP        = 44\n",
      "TP + FP   = 50\n",
      "TP + FN   = 256\n",
      "Precision = 0.88\n",
      "Recall    = 0.171875\n",
      "confidence_threshold: 1.0\n",
      "TP        = 0\n",
      "TP + FP   = 0\n",
      "TP + FN   = 256\n",
      "Precision = 0.0\n",
      "Recall    = 0.0\n"
     ]
    }
   ],
   "source": [
    "for confidence_threshold in confidences:\n",
    "    print(f\"confidence_threshold: {confidence_threshold}\")\n",
    "    overall_evaluation(predictions, ground_truths, confidence_threshold, None, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Precision:\n",
      "- Paprika: 0.6793552380589076\n",
      "- Kiwi:    0.6364245076563104\n"
     ]
    }
   ],
   "source": [
    "AP_paprika = np.mean(precisions_paprika)\n",
    "AP_kiwi = np.mean(precisions_kiwi)\n",
    "print(\"Average Precision:\")\n",
    "print(f\"- Paprika: {AP_paprika}\")\n",
    "print(f\"- Kiwi:    {AP_kiwi}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP: 0.657889872857609\n"
     ]
    }
   ],
   "source": [
    "mAP = np.mean([AP_paprika, AP_kiwi])\n",
    "print(f\"mAP: {mAP}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "service_analytics_exercises",
   "language": "python",
   "name": "service_analytics_exercises"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
