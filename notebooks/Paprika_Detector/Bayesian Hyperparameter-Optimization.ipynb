{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup and Imports\n",
    "\n",
    "Additional requirements:\n",
    "- hyperopt 0.2.4\n",
    "- lightgbm 2.3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'../..')  # add project root to PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supress tensorflow depreciation warnings\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from src.model import TinyYoloV3, train_test_split\n",
    "from src.preprocessing import JSONUtil\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from hyperopt import Trials, STATUS_OK, tpe, fmin, hp, atpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../../data/'\n",
    "annotation_data = JSONUtil.read(Path(data_path, \"Master.json\"))\n",
    "weights_path = '../../models/pre_trained_weights/tiny-yoloV3.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the Random Seeds\n",
    "For deterministic execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seeds\n",
    "tf.random.set_random_seed(4321)\n",
    "np.random.seed(1459)\n",
    "split_seed = 2345"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Prepare the Data\n",
    "Split the data into a test, validation and training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train-Test split\n",
    "test_split = 0.1\n",
    "train_val_data, test_data = train_test_split(annotation_data, test_split, split_seed)\n",
    "\n",
    "# Train-Validation split\n",
    "validation_split = 0.2\n",
    "training_data, validation_data = train_test_split(train_val_data, validation_split, split_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning: Freezing followed by fine-tuning the whole model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "lr_freeze = 10**-2\n",
    "lr_fine_tuning = 10**-6\n",
    "epochs_freeze = 10\n",
    "epochs_fine_tuning = 10\n",
    "\n",
    "# Output paths\n",
    "out_path_freeze = \"model_1208.h5\"\n",
    "out_path_fine_tuning = \"model_1208_fine_tune.h5\"\n",
    "out_path_checkpoints =\"weights.best.hdf5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "            'rotation_probability': hp.uniform('rotation_probability', 0, 1),\n",
    "            'jittering_probability': hp.uniform('jittering_probability', 0, 1),\n",
    "            'hue': hp.uniform('hue', 0.1, 1),\n",
    "            'sat': hp.uniform('sat', 0.1, 1.5), \n",
    "            'val': hp.uniform('val', 0.1, 1.5), \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opt_fun(params):\n",
    "    import keras.backend as K  \n",
    "    from keras.callbacks import EarlyStopping, ReduceLROnPlateau,ModelCheckpoint\n",
    "    from src.model import TinyYoloV3\n",
    "    \n",
    "    # set seeds\n",
    "    tf.random.set_random_seed(4321)\n",
    "    np.random.seed(1459)\n",
    "    split_seed = 2345\n",
    "    \n",
    "    # fix these parameters for faster learning of jittering paramters\n",
    "    epochs_freeze = 15\n",
    "    batch_size = 16\n",
    "    \n",
    "    jittering_params = {\n",
    "        \"rotation_probability\": params[\"rotation_probability\"],\n",
    "        \"jittering_probability\": params[\"jittering_probability\"],\n",
    "        \"jittering_range\": {\n",
    "            \"hue\": params[\"hue\"],\n",
    "            \"sat\": params[\"sat\"],\n",
    "            \"val\": params[\"val\"]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Set Keras to learning-mode --> fix constantly adapting batch-normalizations\n",
    "    K.set_learning_phase(1)\n",
    "\n",
    "    # Setup Model\n",
    "    model = TinyYoloV3(path = weights_path, pre_trained_weights = True)\n",
    "    model.replace_output_layers()\n",
    "    model.training_mode()\n",
    "    \n",
    "    # Define the Callbacks\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3, restore_best_weights = True)\n",
    "    checkpoint = ModelCheckpoint(out_path_checkpoints, monitor='val_loss', verbose=0, save_best_only=True)\n",
    "    callbacks = [early_stopping, checkpoint]\n",
    "    \n",
    "    \n",
    "    # freeze selected layers\n",
    "    model.freeze_all_but_output()\n",
    "\n",
    "    # start training (Transfer Learning)\n",
    "    history_freeze = model.train(training_data, validation_data, data_path, lr_freeze, batch_size, \n",
    "                                 epochs_freeze, out_path=out_path_freeze, callbacks = callbacks, \n",
    "                                 jittering_params = jittering_params, verbose=0)\n",
    "    \n",
    "    # obtain val-error\n",
    "    score = model.evaluate(validation_data, data_path)\n",
    "    \n",
    "    # display params\n",
    "    print(params, score)\n",
    "    \n",
    "    return {'loss': score, 'status': STATUS_OK, 'model': model, 'params': params}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rounds\n",
    "max_evals = 15\n",
    "\n",
    "### optimization\n",
    "trials = Trials()\n",
    "best = fmin(fn = opt_fun, space = space, algo= atpe.suggest, max_evals= max_evals, trials=trials, rstate= np.random.RandomState(2222))\n",
    "print('best: ')\n",
    "### Extract params\n",
    "print(trials.results[np.argmin([r['loss'] for r in trials.results])]['params'])\n",
    "# Extract Model\n",
    "model =trials.results[np.argmin([r['loss'] for r in trials.results])]['model']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Model: Obtain the Train and Test Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain train-error\n",
    "model.evaluate(train_val_data, data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain test-error\n",
    "model.evaluate(test_data, data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
